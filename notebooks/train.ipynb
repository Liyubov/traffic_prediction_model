{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Добавляем путь на уровень выше\n",
    "sys.path.append(str(Path(os.getcwd()).resolve().parent))\n",
    "\n",
    "from utils.features import *\n",
    "from utils.load_data import load_all_data\n",
    "from utils.feature_engineering import add_features\n",
    "from utils.graph_features import GraphClusterProcessor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/PEMS03')\n",
    "metadata, data, adj = load_all_data(data_dir)\n",
    "data = data[:2016]\n",
    "data = data.copy()\n",
    "\n",
    "data[:, :, 1] = data[:, :, 1] * 288\n",
    "data[:, :, 2] = data[:, :, 2] * 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходные данные (временные ряды): (2016, 358, 3)\n",
      "Эмбеддинги узлов: (2016, 358, 12)\n",
      "Объединённые данные: (2016, 358, 15)\n"
     ]
    }
   ],
   "source": [
    "def lagged_feature(data, lags=[1,2,3]):\n",
    "    \"\"\"Добавляет лаггированные признаки для данных.\"\"\"\n",
    "    data_lagged = []\n",
    "    for lag in lags:\n",
    "        lagged_data = np.roll(data, shift=lag, axis=0)  # Сдвигаем данные на заданное количество шагов\n",
    "        lagged_data[:lag] = 0  # Заполняем пропуски нулями\n",
    "        data_lagged.append(lagged_data)\n",
    "    \n",
    "    # Объединяем оригинальные данные с лагами\n",
    "    data_lagged = np.concatenate(data_lagged, axis=-1)\n",
    "    \n",
    "    return data_lagged\n",
    "\n",
    "lagged_data = lagged_feature(data[:, :, :1], lags=[1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "\n",
    "data_expanded = np.concatenate([data, lagged_data], axis=-1)  # Форма: (2016, 325, 3 + 1)\n",
    "\n",
    "# Проверка результата\n",
    "print(\"Исходные данные (временные ряды):\", data.shape)\n",
    "print(\"Эмбеддинги узлов:\", lagged_data.shape)\n",
    "print(\"Объединённые данные:\", data_expanded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prepend': [0, 0], 'n': 2}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 3 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(kwargs)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdiff(data, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, prepend\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprepend\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39m_NoValue), n\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m \u001b[43mderivative_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# data_expanded = np.concatenate([data, derivative_data], axis=-1)  # Форма: (2016, 325, 3 + 1)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# # Проверка результата\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# print(\"Исходные данные (временные ряды):\", data.shape)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(\"Эмбеддинги узлов:\", derivative_data.shape)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print(\"Объединённые данные:\", data_expanded.shape)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m, in \u001b[0;36mderivative_feature\u001b[1;34m(data, **kwargs)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Производная.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(kwargs)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprepend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_NoValue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Github\\traffic_prediction_model\\.venv\\Lib\\site-packages\\numpy\\lib\\function_base.py:1441\u001b[0m, in \u001b[0;36mdiff\u001b[1;34m(a, n, axis, prepend, append)\u001b[0m\n\u001b[0;32m   1438\u001b[0m     combined\u001b[38;5;241m.\u001b[39mappend(append)\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(combined) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1441\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1443\u001b[0m slice1 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m*\u001b[39m nd\n\u001b[0;32m   1444\u001b[0m slice2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m*\u001b[39m nd\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 3 dimension(s)"
     ]
    }
   ],
   "source": [
    "def derivative_feature(data, **kwargs):\n",
    "    \"\"\"Производная.\"\"\"\n",
    "    print(kwargs)\n",
    "    return np.diff(data, axis=0, prepend=kwargs.get('prepend', np._NoValue), n=kwargs.get('n', 1))\n",
    "\n",
    "derivative_feature(data[:, :, :1], prepend=[0,0], n=2).shape\n",
    "\n",
    "# data_expanded = np.concatenate([data, derivative_data], axis=-1)  # Форма: (2016, 325, 3 + 1)\n",
    "\n",
    "# # Проверка результата\n",
    "# print(\"Исходные данные (временные ряды):\", data.shape)\n",
    "# print(\"Эмбеддинги узлов:\", derivative_data.shape)\n",
    "# print(\"Объединённые данные:\", data_expanded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphClusterProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = GraphClusterProcessor(adj, data)\n",
    "processor.elbow_method(metric='PageRank', max_clusters=15)\n",
    "\n",
    "labels = KMeans(n_clusters=3, random_state=42).fit_predict(\n",
    "    np.array(list(nx.betweenness_centrality(nx.from_numpy_array(adj)).values())).reshape(-1, 1)\n",
    ")\n",
    "processor.plot_group_average_speeds(labels, n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_expanded = processor.cluster_and_add_channel(metric='PageRank', n_clusters=3, one_hot=True, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение функций\n",
    "feature_functions = {\n",
    "    # 'minute': minute_index_feature,\n",
    "    # 'weekday': weekday_index_feature,\n",
    "    # 'fft': fft_denoise_feature,\n",
    "    # 'mean': mean_feature,\n",
    "    # 'median': median_feature,\n",
    "    # 'std': std_feature,\n",
    "    # 'min': min_feature,\n",
    "    # 'max': max_feature,\n",
    "    # 'kurtosis': kurtosis_feature,\n",
    "    # 'skew': skew_feature,\n",
    "    # 'quantile': quantile_feature,\n",
    "    # 'rolling_mean': rolling_mean_feature,\n",
    "    # 'rolling_std': rolling_std_feature,\n",
    "    # 'rolling_min': rolling_min_feature,\n",
    "    # 'rolling_max': rolling_max_feature,\n",
    "    # 'derivative': derivative_feature,\n",
    "}\n",
    "\n",
    "graph_feature_functions = {\n",
    "    # 'degree': degree_feature,\n",
    "    # 'node_index': node_indices_feature,\n",
    "    # 'degree_centrality': degree_centrality_feature,\n",
    "    # 'closeness_centrality': closeness_centrality_feature,\n",
    "    # 'betweenness_centrality': betweenness_centrality_feature,\n",
    "    'clustering_coefficient': clustering_coefficient_feature,\n",
    "}\n",
    "\n",
    "# Добавление фичей для train\n",
    "data_expanded = add_features(\n",
    "    data,\n",
    "    feature_list=list(feature_functions.keys()),\n",
    "    feature_functions=feature_functions,\n",
    "    graph_feature_functions=graph_feature_functions,\n",
    "    index=None,\n",
    "    adj_matrix=adj\n",
    ")\n",
    "\n",
    "data_expanded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_indices = np.array([i for i in range(data.shape[1])])\n",
    "node_indices_expanded = np.expand_dims(node_indices, axis=0)  # Форма: (1, 325,)\n",
    "node_indices_expanded = np.expand_dims(node_indices_expanded, axis=-1)  # Форма: (1, 325, 1)\n",
    "node_indices_expanded = np.repeat(node_indices_expanded, data.shape[0], axis=0)  # Форма: (2016, 325, 1)\n",
    "\n",
    "# Объединение с временными рядами по последней оси\n",
    "data_expanded = np.concatenate([data, node_indices_expanded], axis=-1)  # Форма: (2016, 325, 3 + 1)\n",
    "\n",
    "# Проверка результата\n",
    "print(\"Исходные данные (временные ряды):\", data.shape)\n",
    "print(\"Эмбеддинги узлов:\", node_indices.shape)\n",
    "print(\"Объединённые данные:\", data_expanded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(adj, 0)\n",
    "G = nx.from_numpy_array(adj)\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=400, p=1, q=1, workers=12)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "node_embeddings = np.array([model.wv[str(node)] for node in G.nodes()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings_expanded = np.expand_dims(node_embeddings, axis=0)  # Форма: (1, 325, 64)\n",
    "node_embeddings_expanded = np.repeat(node_embeddings_expanded, data.shape[0], axis=0)  # Форма: (2016, 325, 64)\n",
    "\n",
    "# 4. Объединение с временными рядами по последней оси\n",
    "data_expanded = np.concatenate([data, node_embeddings_expanded], axis=-1)  # Форма: (2016, 325, 3 + 64)\n",
    "\n",
    "# 5. Проверка результата\n",
    "print(\"Исходные данные (временные ряды):\", data.shape)\n",
    "print(\"Эмбеддинги узлов:\", node_embeddings.shape)\n",
    "print(\"Объединённые данные:\", data_expanded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position Encoding (PE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    position = np.arange(pos)[:, np.newaxis]\n",
    "    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "    pe = np.zeros((pos, d_model))\n",
    "    pe[:, 0::2] = np.sin(position * div_term)\n",
    "    pe[:, 1::2] = np.cos(position * div_term)\n",
    "    return pe\n",
    "\n",
    "# Пример для 325 узлов\n",
    "num_nodes = data.shape[1]\n",
    "d_model = 16\n",
    "pe = positional_encoding(num_nodes, d_model)  # Форма: (325, 64)\n",
    "\n",
    "# Расширение до (batch_size, 325, 64)\n",
    "pe = positional_encoding(num_nodes, d_model).astype(np.float32)  # Используйте float32\n",
    "pe_expanded = np.expand_dims(pe, axis=0)  # Форма: (1, 325, 64)\n",
    "pe_expanded = np.repeat(pe_expanded, data.shape[0], axis=0)  # Форма: (2016, 325, 64)\n",
    "pe_expanded = torch.tensor(pe_expanded, dtype=torch.float32)     # Для тензоров\n",
    "\n",
    "data_expanded = np.concatenate([data, pe_expanded], axis=-1)  # Форма: (2016, 325, 3 + 64)\n",
    "\n",
    "# 5. Проверка результата\n",
    "print(\"Исходные данные (временные ряды):\", data.shape)\n",
    "print(\"Эмбеддинги узлов:\", pe_expanded.shape)\n",
    "print(\"Объединённые данные:\", data_expanded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных и создание Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные и параметры\n",
    "L, N, C = data_expanded.shape  # [2016, 325, C]\n",
    "batch_size = 16\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "seq_len = 12  # Количество временных шагов на вход\n",
    "pred_len = 12  # Количество временных шагов для предсказания\n",
    "\n",
    "# Индексы каналов для нормализации\n",
    "normalize = True\n",
    "\n",
    "channels_to_normalize = [0,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "\n",
    "# Проверка корректности разделения данных\n",
    "assert train_ratio + val_ratio + test_ratio == 1.0, \"Сумма долей train, val и test должна быть равна 1.0\"\n",
    "\n",
    "# Разделение данных на train, val и test\n",
    "num_samples = data_expanded.shape[0]  # Количество временных шагов (L)\n",
    "train_size = int(num_samples * train_ratio)\n",
    "val_size = int(num_samples * val_ratio)\n",
    "test_size = num_samples - train_size - val_size\n",
    "\n",
    "train_data = data_expanded[:train_size, :, :]  # [train_size, N, C]\n",
    "val_data = data_expanded[train_size:train_size + val_size, :, :]  # [val_size, N, C]\n",
    "test_data = data_expanded[train_size + val_size:, :, :]  # [test_size, N, C]\n",
    "\n",
    "# Нормализация данных\n",
    "if normalize:\n",
    "    assert all(0 <= ch < C for ch in channels_to_normalize), \"Индексы каналов выходят за пределы допустимого диапазона\"\n",
    "    channel_max = train_data[:, :, channels_to_normalize].max(axis=(0, 1), keepdims=True)  # Форма [1, 1, len(channels_to_normalize)]\n",
    "    channel_max[channel_max == 0] = 1.0\n",
    "    train_data[:, :, channels_to_normalize] = train_data[:, :, channels_to_normalize] / channel_max\n",
    "    val_data[:, :, channels_to_normalize] = val_data[:, :, channels_to_normalize] / channel_max\n",
    "    test_data[:, :, channels_to_normalize] = test_data[:, :, channels_to_normalize] / channel_max\n",
    "\n",
    "# Создание кастомного Dataset\n",
    "class TrafficDataset(Dataset):\n",
    "    def __init__(self, data, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.data = data  # Форма [L, N, C]\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "    def __len__(self):\n",
    "        # Количество возможных последовательностей\n",
    "        return self.data.shape[0] - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Извлекаем последовательность входных данных\n",
    "        x = self.data[idx:idx + self.seq_len, :, :]  # Форма [seq_len, N, C]\n",
    "        # Извлекаем целевую последовательность\n",
    "        y = self.data[idx + self.seq_len:idx + self.seq_len + self.pred_len, :, 0]  # Форма [pred_len, N, C]\n",
    "        return x, y\n",
    "    \n",
    "# Преобразование данных в тензоры с dtype=torch.float32\n",
    "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "val_data = torch.tensor(val_data, dtype=torch.float32)\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "\n",
    "# Создание DataLoader\n",
    "train_dataset = TrafficDataset(train_data, seq_len, pred_len)\n",
    "val_dataset = TrafficDataset(val_data, seq_len, pred_len)\n",
    "test_dataset = TrafficDataset(test_data, seq_len, pred_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x (input data):    torch.Size([16, 12, 358, 15])\n",
      "Shape of y (target data):   torch.Size([16, 12, 358])\n",
      "\n",
      "First two sensors and time steps in x:\n",
      "tensor([[[1.3402e-01, 1.5800e+02, 3.0000e+00, 1.2715e-01, 1.2371e-01,\n",
      "          1.3660e-01, 1.4175e-01, 1.3144e-01, 1.3918e-01, 1.4003e-01,\n",
      "          1.2973e-01, 1.4089e-01, 1.4519e-01, 1.2973e-01, 1.3058e-01],\n",
      "         [1.3058e-01, 1.5800e+02, 3.0000e+00, 1.3144e-01, 1.2027e-01,\n",
      "          1.3058e-01, 1.3660e-01, 1.2629e-01, 1.3402e-01, 1.3660e-01,\n",
      "          1.2801e-01, 1.3832e-01, 1.3746e-01, 1.2543e-01, 1.3144e-01]],\n",
      "\n",
      "        [[1.3660e-01, 1.5900e+02, 3.0000e+00, 1.3402e-01, 1.2715e-01,\n",
      "          1.2371e-01, 1.3660e-01, 1.4175e-01, 1.3144e-01, 1.3918e-01,\n",
      "          1.4003e-01, 1.2973e-01, 1.4089e-01, 1.4519e-01, 1.2973e-01],\n",
      "         [1.3488e-01, 1.5900e+02, 3.0000e+00, 1.3058e-01, 1.3144e-01,\n",
      "          1.2027e-01, 1.3058e-01, 1.3660e-01, 1.2629e-01, 1.3402e-01,\n",
      "          1.3660e-01, 1.2801e-01, 1.3832e-01, 1.3746e-01, 1.2543e-01]]])\n",
      "\n",
      "First two sensors and time steps in y:\n",
      "tensor([[0.1383, 0.1366],\n",
      "        [0.1503, 0.1426]])\n",
      "\n",
      "Data types for each channel in x:\n",
      "Channel 0 dtype: torch.float32, device: cpu\n",
      "Channel 1 dtype: torch.float32, device: cpu\n",
      "Channel 2 dtype: torch.float32, device: cpu\n",
      "Channel 3 dtype: torch.float32, device: cpu\n",
      "Channel 4 dtype: torch.float32, device: cpu\n",
      "Channel 5 dtype: torch.float32, device: cpu\n",
      "Channel 6 dtype: torch.float32, device: cpu\n",
      "Channel 7 dtype: torch.float32, device: cpu\n",
      "Channel 8 dtype: torch.float32, device: cpu\n",
      "Channel 9 dtype: torch.float32, device: cpu\n",
      "Channel 10 dtype: torch.float32, device: cpu\n",
      "Channel 11 dtype: torch.float32, device: cpu\n",
      "Channel 12 dtype: torch.float32, device: cpu\n",
      "Channel 13 dtype: torch.float32, device: cpu\n",
      "Channel 14 dtype: torch.float32, device: cpu\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(f\"Shape of x (input data):    {x.shape}\")  # [B, L, N, C]\n",
    "    print(f\"Shape of y (target data):   {y.shape}\")  # [B, L, N]\n",
    "\n",
    "    # Проверка первых двух сенсоров и временных шагов\n",
    "    print(\"\\nFirst two sensors and time steps in x:\")\n",
    "    print(x[0, :2, :2, :])  # Первый батч, первые два временных шага, первые два сенсора, все каналы\n",
    "\n",
    "    print(\"\\nFirst two sensors and time steps in y:\")\n",
    "    print(y[0, :2, :2])  # Первый батч, первые два временных шага, первые два сенсора\n",
    "\n",
    "    # Проверка типов данных для всех каналов\n",
    "    print(\"\\nData types for each channel in x:\")\n",
    "    for channel in range(x.shape[3]):  # Проходим по всем каналам\n",
    "        print(f\"Channel {channel} dtype: {x[0, 0, 0, channel].dtype}, device: {x[0, 0, 0, channel].device}\")\n",
    "\n",
    "    # Остановка выполнения для ручной проверки\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация моделей и запуск обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "def normalize_directed_adj(adj, mode='row'):\n",
    "    adj = adj + torch.eye(adj.size(0)).to(adj.device)\n",
    "    if mode == 'row':\n",
    "        degree = torch.sum(adj, dim=1, keepdim=True)\n",
    "    elif mode == 'col':\n",
    "        degree = torch.sum(adj, dim=0, keepdim=True)\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be 'row' or 'col'.\")\n",
    "    \n",
    "    degree_inv = torch.where(degree > 0, 1.0 / degree, torch.zeros_like(degree))\n",
    "    return adj * degree_inv\n",
    "\n",
    "def normalize_adj(adj_batch):\n",
    "    \"\"\"\n",
    "    adj_batch: [B, N, N] или [N, N]\n",
    "    Возвращает: [B, N, N] с симметричной нормализацией для каждого графа в батче\n",
    "    \"\"\"\n",
    "    if adj_batch.dim() == 2:\n",
    "        adj_batch = adj_batch.unsqueeze(0)  # Добавляем размерность батча\n",
    "\n",
    "    B, N, _ = adj_batch.shape\n",
    "    identity = torch.eye(N).unsqueeze(0).expand(B, -1, -1).to(adj_batch.device)\n",
    "    adj_batch = adj_batch + identity\n",
    "    degree = adj_batch.sum(dim=2)  # [B, N]\n",
    "    degree_inv_sqrt = torch.where(degree > 0, degree.pow(-0.5), torch.zeros_like(degree))  # [B, N]\n",
    "    D_inv_sqrt = degree_inv_sqrt.unsqueeze(2) * torch.eye(N).unsqueeze(0).to(adj_batch.device)\n",
    "    adj_normalized = torch.bmm(torch.bmm(D_inv_sqrt, adj_batch), D_inv_sqrt)\n",
    "    \n",
    "    return adj_normalized.squeeze(0) if adj_batch.dim() == 3 and B == 1 else adj_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QGNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGNNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, num_nodes, dropout=0.5, act=F.tanh):\n",
    "        super(QGNNLayer, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.act = act\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.bn = nn.BatchNorm1d(out_features)\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = math.sqrt(6.0 / (self.weight.size(0) + self.weight.size(1)))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        x = self.dropout(x)\n",
    "        support = torch.mm(x, self.weight)\n",
    "      \n",
    "        B_N, hidden_dim = support.shape\n",
    "        B = B_N // self.num_nodes\n",
    "        N = self.num_nodes\n",
    "        support = support.view(B, N, hidden_dim)\n",
    "        output = torch.bmm(adj, support)\n",
    "        output = output.view(B * N, hidden_dim)\n",
    "        output = self.bn(output)\n",
    "        output = self.act(output)\n",
    "        return output\n",
    "\n",
    "class QGNNTrafficPredictor(nn.Module):\n",
    "    def __init__(self, adj, num_nodes, input_dim, hidden_dim, output_dim, num_layers, pre_len, emb_configs, dropout=0.5, directed=False):\n",
    "        \"\"\"\n",
    "        adj: матрица смежности\n",
    "        num_nodes: количество узлов\n",
    "        input_dim: размерность входных данных (без учёта эмбеддингов)\n",
    "        hidden_dim: размер скрытого слоя\n",
    "        output_dim: размер выходного слоя\n",
    "        num_layers: количество GNN-слоёв\n",
    "        pre_len: длина предсказания\n",
    "        emb_configs: словарь {канал: (num_embeddings, embedding_dim)}\n",
    "        dropout: коэффициент дропаута\n",
    "        \"\"\"\n",
    "        super(QGNNTrafficPredictor, self).__init__()\n",
    "        # self.adj = normalize_directed_adj(adj) if directed else normalize_adj(adj)\n",
    "        self.pre_len = pre_len\n",
    "        self.num_nodes = num_nodes\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.base_adj = adj\n",
    "        self.window_size = pre_len  # 1 час (12 * 5 мин)\n",
    "        self.alpha = 0.7  # Вес для базовой матрицы\n",
    "\n",
    "\n",
    "        # Инициализация эмбеддингов\n",
    "        self.embeddings = nn.ModuleDict({\n",
    "            f\"emb_{channel}\": nn.Embedding(num_embeddings, emb_dim)\n",
    "            for channel, (num_embeddings, emb_dim) in emb_configs.items()\n",
    "        })\n",
    "\n",
    "        total_emb_dim = sum(emb_dim for _, (_, emb_dim) in emb_configs.items())\n",
    "\n",
    "        # QGNN слои\n",
    "        self.qgnn_layers = nn.ModuleList([\n",
    "            QGNNLayer(input_dim if i == 0 else hidden_dim, hidden_dim, self.num_nodes, dropout)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # GRU\n",
    "        self.temporal_layer = nn.GRU(hidden_dim + total_emb_dim + 1, hidden_dim, batch_first=True)\n",
    "        self.relu = F.relu\n",
    "\n",
    "        # FC\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def compute_dynamic_adj(self, X):\n",
    "        \"\"\"X: [B, N, L, 1] (speed)\"\"\"\n",
    "        B, N, L, _ = X.shape\n",
    "        \n",
    "        # Векторизованный расчет корреляции\n",
    "        if L >= self.window_size:\n",
    "            data_window = X[:, :, -self.window_size:, 0]  # [B, N, window_size]\n",
    "            data_centered = data_window - data_window.mean(dim=2, keepdim=True)\n",
    "            cov = torch.matmul(data_centered, data_centered.transpose(1, 2))  # [B, N, N]\n",
    "            std = torch.sqrt(torch.sum(data_centered**2, dim=2))  # [B, N]\n",
    "            corr = cov / (std.unsqueeze(1) * std.unsqueeze(2) + 1e-8)  # [B, N, N]\n",
    "        else:\n",
    "            corr = torch.eye(N).unsqueeze(0).expand(B, -1, -1).to(X.device)\n",
    "        \n",
    "        # Комбинация с базовой матрицей\n",
    "        base_adj = self.base_adj.unsqueeze(0).expand(B, -1, -1)  # [B, N, N]\n",
    "        adj = self.alpha * base_adj + (1 - self.alpha) * corr\n",
    "        \n",
    "        return normalize_adj(adj)  # Нормализация всего батча\n",
    "\n",
    "    def forward(self, history_data, removed_channel=None):\n",
    "        \"\"\"\n",
    "        history_data: [B, L, N, C] - тензор временных рядов (где некоторые каналы содержат индексы эмбеддингов)\n",
    "        removed_channel: индекс канала, который нужно исключить\n",
    "        \"\"\"\n",
    "        B, L, N, C = history_data.shape\n",
    "\n",
    "        # Создание маски для исключения канала\n",
    "        if removed_channel is not None:\n",
    "            mask = torch.ones(C).to(history_data.device)\n",
    "            mask[removed_channel] = 0  # Отключаем канал\n",
    "            history_data = history_data * mask  # Применяем маску к данным\n",
    "\n",
    "        history_data = history_data.permute(0, 2, 1, 3)     # [B, N, L, C]\n",
    "        speed = history_data[:, :, :, :1]                   # [B, N, L, 1]\n",
    "\n",
    "        # Обрабатываем эмбеддинги, используя индексы из history_data\n",
    "        emb_list = []\n",
    "        for channel, emb_layer in self.embeddings.items():\n",
    "            channel_idx = int(channel.split(\"_\")[1])                    # Получаем номер канала\n",
    "            emb_indices = history_data[:, :, :, channel_idx].long()     # [B, N, L]\n",
    "            emb_list.append(emb_layer(emb_indices))                     # [B, N, L, emb_dim]\n",
    "\n",
    "        emb_concat = torch.cat(emb_list, dim=-1) if emb_list else None  # [B, N, L, total_emb_dim]\n",
    "        dynamic_adj = self.compute_dynamic_adj(history_data[..., :1])\n",
    "\n",
    "        outputs = []\n",
    "        for t in range(L):\n",
    "            x = history_data[:, :, t, :1]           # [B,  N, 1]\n",
    "            x = x.reshape(B * N, -1)                # [B * N, 1]\n",
    "            for qgnn_layer in self.qgnn_layers:\n",
    "                x = qgnn_layer(x, dynamic_adj)      # [B * N, hidden_dim]\n",
    "            x = x.reshape(B, N, -1)                 # [B,  N, hidden_dim]\n",
    "            outputs.append(x)\n",
    "        outputs = torch.stack(outputs, dim=2)       # [B,  N, L, hidden_dim]\n",
    "\n",
    "        # Добавляем эмбеддинги\n",
    "        if emb_concat is not None:\n",
    "            outputs = torch.cat([speed, outputs, emb_concat], dim=-1)  # [B, N, L, hidden_dim + total_emb_dim]\n",
    "        else:\n",
    "            outputs = torch.cat([speed, outputs], dim=-1)\n",
    "\n",
    "        # Применяем GRU\n",
    "        outputs = outputs.reshape(B * N, L, -1)     # [B * N, L, hidden_dim + total_emb_dim]\n",
    "        outputs, _ = self.temporal_layer(outputs)   # [B * N, L, hidden_dim]\n",
    "        outputs = outputs.reshape(B, N, L, -1)      # [B,  N, L, hidden_dim]\n",
    "        outputs = outputs[:, :, -self.pre_len:, :]  # [B,  N, pre_len, hidden_dim]\n",
    "        outputs = self.relu(outputs)\n",
    "\n",
    "        # Выходной слой\n",
    "        outputs = self.fc1(outputs)         # [B, N, pre_len, output_dim]\n",
    "        outputs = self.fc2(outputs)         # [B, N, pre_len, output_dim]\n",
    "        return outputs.permute(0, 2, 1, 3)  # [B, pre_len, N, output_dim]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFDGCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class convt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convt, self).__init__()\n",
    "\n",
    "    def forward(self, x, w):\n",
    "        x = torch.einsum('bne, ek->bnk', (x, w))\n",
    "        return x.contiguous()\n",
    "class nconv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(nconv, self).__init__()\n",
    "\n",
    "    def forward(self, x, A, dims):\n",
    "        if dims == 2:\n",
    "            x = torch.einsum('ncvl,vw->ncwl', (x, A))\n",
    "        elif dims == 3:\n",
    "            x = torch.einsum('ncvl,nvw->ncwl', (x, A))\n",
    "        else:\n",
    "            raise NotImplementedError('DFDGCN not implemented for A of dimension ' + str(dims))\n",
    "        return x.contiguous()\n",
    "\n",
    "class linear(nn.Module):\n",
    "    \"\"\"Linear layer.\"\"\"\n",
    "\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(linear, self).__init__()\n",
    "        self.mlp = torch.nn.Conv2d(c_in, c_out, kernel_size=(\n",
    "            1, 1), padding=(0, 0), stride=(1, 1), bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "class gcn(nn.Module):\n",
    "    \"\"\"Graph convolution network.\"\"\"\n",
    "\n",
    "    def __init__(self, c_in, c_out, dropout, support_len=3, order=2):\n",
    "        super(gcn, self).__init__()\n",
    "        self.nconv = nconv()\n",
    "\n",
    "        self.c_in = c_in\n",
    "        c_in = (order * (support_len + 1) + 1) * self.c_in\n",
    "        self.mlp = linear(c_in, c_out)\n",
    "        self.dropout = dropout\n",
    "        self.order = order\n",
    "\n",
    "    def forward(self, x, support):\n",
    "\n",
    "        out = [x]\n",
    "        for a in support:\n",
    "            x1 = self.nconv(x, a.to(x.device), a.dim())\n",
    "            out.append(x1)\n",
    "\n",
    "            for k in range(2, self.order + 1):\n",
    "                x2 = self.nconv(x1, a.to(x1.device), a.dim())\n",
    "                out.append(x2)\n",
    "                x1 = x2\n",
    "        h = torch.cat(out, dim=1)\n",
    "        h = self.mlp(h)\n",
    "        h = F.dropout(h, self.dropout, training=self.training)\n",
    "        return h\n",
    "\n",
    "\n",
    "\n",
    "def dy_mask_graph(adj, k):\n",
    "    M = []\n",
    "    for i in range(adj.size(0)):\n",
    "        adp = adj[i]\n",
    "        mask = torch.zeros( adj.size(1),adj.size(2)).to(adj.device)\n",
    "        mask = mask.fill_(float(\"0\"))\n",
    "        s1, t1 = (adp + torch.rand_like(adp) * 0.01).topk(k, 1)\n",
    "        mask = mask.scatter_(1, t1, s1.fill_(1))\n",
    "        M.append(mask)\n",
    "    mask = torch.stack(M,dim=0)\n",
    "    adj = adj * mask\n",
    "    return adj\n",
    "\n",
    "\n",
    "\n",
    "def cat(x1,x2):\n",
    "    M = []\n",
    "    for i in range(x1.size(0)):\n",
    "        x = x1[i]\n",
    "        new_x = torch.cat([x,x2],dim=1)\n",
    "        M.append(new_x)\n",
    "    result = torch.stack(M,dim=0)\n",
    "    return result\n",
    "\n",
    "\n",
    "class DFDGCN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_nodes, dropout=0.3, supports=None,\n",
    "                    gcn_bool=True, addaptadj=True, aptinit=None,\n",
    "                    in_dim=2, out_dim=12, residual_channels=32,\n",
    "                    dilation_channels=32, skip_channels=256, end_channels=512,\n",
    "                    kernel_size=2, blocks=4, layers=2, a=1, seq_len=12, affine=True, fft_emb=10, identity_emb=10, hidden_emb=30, subgraph=20, alpha=0.7, window_size=3):\n",
    "        super(DFDGCN, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.alpha = alpha\n",
    "        self.dropout = dropout\n",
    "        self.blocks = blocks\n",
    "        self.layers = layers\n",
    "        self.gcn_bool = gcn_bool\n",
    "        self.addaptadj = addaptadj\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs = nn.ModuleList()\n",
    "        self.residual_convs = nn.ModuleList()\n",
    "        self.skip_convs = nn.ModuleList()\n",
    "        self.bn = nn.ModuleList()\n",
    "        self.gconv = nn.ModuleList()\n",
    "        self.seq_len = seq_len\n",
    "        self.a = a\n",
    "\n",
    "        self.start_conv = nn.Conv2d(in_channels=in_dim,\n",
    "                                    out_channels=residual_channels,\n",
    "                                    kernel_size=(1, 1))\n",
    "\n",
    "        self.supports = supports\n",
    "        self.emb = fft_emb\n",
    "        self.subgraph_size = subgraph\n",
    "        self.identity_emb = identity_emb\n",
    "        self.hidden_emb = hidden_emb\n",
    "        self.fft_len = round(seq_len//2) + 1\n",
    "        self.Ex1 = nn.Parameter(torch.randn(self.fft_len, self.emb), requires_grad=True)\n",
    "        self.Wd = nn.Parameter(torch.randn(num_nodes,self.emb + self.identity_emb + self.seq_len * 2, self.hidden_emb), requires_grad=True)\n",
    "        self.Wxabs = nn.Parameter(torch.randn(self.hidden_emb, self.hidden_emb), requires_grad=True)\n",
    "\n",
    "        self.mlp = linear(residual_channels * 4,residual_channels)\n",
    "        self.layersnorm = torch.nn.LayerNorm(normalized_shape=[num_nodes,self.hidden_emb], eps=1e-08,elementwise_affine=affine)\n",
    "        self.convt = convt()\n",
    "\n",
    "        self.node1 = nn.Parameter(\n",
    "            torch.randn(num_nodes, self.identity_emb), requires_grad=True)\n",
    "        self.drop = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.T_i_D_emb = nn.Parameter(\n",
    "            torch.empty(288, self.seq_len))\n",
    "        self.D_i_W_emb = nn.Parameter(\n",
    "            torch.empty(7, self.seq_len))\n",
    "\n",
    "        receptive_field = 1\n",
    "        self.reset_parameter()\n",
    "        self.supports_len = 0\n",
    "        if not addaptadj:\n",
    "            self.supports_len -= 1\n",
    "        if supports is not None:\n",
    "            self.supports_len += len(supports)\n",
    "        if gcn_bool and addaptadj:\n",
    "            if aptinit is None:\n",
    "                if supports is None:\n",
    "                    self.supports = []\n",
    "                self.nodevec1 = nn.Parameter(\n",
    "                    torch.randn(num_nodes, self.emb), requires_grad=True)\n",
    "                self.nodevec2 = nn.Parameter(\n",
    "                    torch.randn(self.emb, num_nodes), requires_grad=True)\n",
    "                self.supports_len += 1\n",
    "            else:\n",
    "                if supports is None:\n",
    "                    self.supports = []\n",
    "                m, p, n = torch.svd(aptinit)\n",
    "                initemb1 = torch.mm(m[:, :10], torch.diag(p[:10] ** 0.5))\n",
    "                initemb2 = torch.mm(torch.diag(p[:10] ** 0.5), n[:, :10].t())\n",
    "                self.nodevec1 = nn.Parameter(initemb1, requires_grad=True)\n",
    "                self.nodevec2 = nn.Parameter(initemb2, requires_grad=True)\n",
    "                self.supports_len += 1\n",
    "\n",
    "        for b in range(blocks):\n",
    "            additional_scope = kernel_size - 1\n",
    "            new_dilation = 1\n",
    "            for i in range(layers):\n",
    "                # dilated convolutions\n",
    "                self.filter_convs.append(nn.Conv2d(in_channels=residual_channels,\n",
    "                                                   out_channels=dilation_channels,\n",
    "                                                   kernel_size=(1, kernel_size), dilation=new_dilation))\n",
    "\n",
    "                self.gate_convs.append(nn.Conv2d(in_channels=residual_channels,\n",
    "                                                 out_channels=dilation_channels,\n",
    "                                                 kernel_size=(1, kernel_size), dilation=new_dilation))\n",
    "\n",
    "                # 1x1 convolution for residual connection\n",
    "                self.residual_convs.append(nn.Conv2d(in_channels=dilation_channels,\n",
    "                                                     out_channels=residual_channels,\n",
    "                                                     kernel_size=(1, 1)))\n",
    "\n",
    "                # 1x1 convolution for skip connection\n",
    "                self.skip_convs.append(nn.Conv2d(in_channels=dilation_channels,\n",
    "                                                 out_channels=skip_channels,\n",
    "                                                 kernel_size=(1, 1)))\n",
    "                self.bn.append(nn.BatchNorm2d(residual_channels))\n",
    "                new_dilation *= 2\n",
    "                receptive_field += additional_scope\n",
    "                additional_scope *= 2\n",
    "                if self.gcn_bool:\n",
    "                    self.gconv.append(\n",
    "                        gcn(dilation_channels, residual_channels, dropout, support_len=self.supports_len))\n",
    "        self.end_conv_1 = nn.Conv2d(in_channels=skip_channels,\n",
    "                                    out_channels=end_channels,\n",
    "                                    kernel_size=(1, 1),\n",
    "                                    bias=True)\n",
    "\n",
    "        self.end_conv_2 = nn.Conv2d(in_channels=end_channels,\n",
    "                                    out_channels=out_dim,\n",
    "                                    kernel_size=(1, 1),\n",
    "                                    bias=True)\n",
    "\n",
    "        self.receptive_field = receptive_field\n",
    "\n",
    "    def reset_parameter(self):\n",
    "        nn.init.xavier_uniform_(self.T_i_D_emb)\n",
    "        nn.init.xavier_uniform_(self.D_i_W_emb)\n",
    "\n",
    "    def compute_dynamic_adj(self, X):\n",
    "        \"\"\"X: [B, L, N, C] (speed)\"\"\"\n",
    "        B, N, L, C = X.shape\n",
    "        X = X.permute(0, 2, 1, 3)\n",
    "        \n",
    "        # Векторизованный расчет корреляции\n",
    "        if L >= self.window_size:\n",
    "            data_window = X[:, :, -self.window_size:, 0]  # [B, window_size, N]\n",
    "            data_centered = data_window - data_window.mean(dim=2, keepdim=True)\n",
    "            cov = torch.matmul(data_centered, data_centered.transpose(1, 2))  # [B, N, N]\n",
    "            std = torch.sqrt(torch.sum(data_centered**2, dim=2))  # [B, N]\n",
    "            corr = cov / (std.unsqueeze(1) * std.unsqueeze(2) + 1e-8)  # [B, N, N]\n",
    "        else:\n",
    "            corr = torch.eye(N).unsqueeze(0).expand(B, -1, -1).to(X.device)\n",
    "        \n",
    "        # Комбинация с базовой матрицей\n",
    "        base_adj = self.supports[0].unsqueeze(0).expand(B, -1, -1)  # [B, N, N]\n",
    "        adj = self.alpha * base_adj + (1 - self.alpha) * corr\n",
    "        \n",
    "        return normalize_adj(adj)  # Нормализация всего батча\n",
    "\n",
    "\n",
    "    def forward(self, history_data: torch.Tensor) -> torch.Tensor: # , future_data: torch.Tensor, batch_seen: int, epoch: int, train: bool, **kwargs\n",
    "        \"\"\"Feedforward function of DFDGCN; Based on Graph WaveNet\n",
    "\n",
    "        Args:\n",
    "            history_data (torch.Tensor): shape [B, L, N, C]\n",
    "\n",
    "        Graphs:\n",
    "            predefined graphs: two graphs; [2, N, N] : Pre-given graph structure, including in-degree and out-degree graphs\n",
    "\n",
    "            self-adaptive graph: [N, N] : Self-Adaptively constructed graphs with two learnable parameters\n",
    "                torch.mm(self.nodevec1, self.nodevec2)\n",
    "                    nodevec: [N, Emb]\n",
    "\n",
    "            dynamic frequency domain graph: [B, N, N] : Data-driven graphs constructed with frequency domain information from traffic data\n",
    "                traffic_data : [B, N, L]\n",
    "                frequency domain information : [B, N, L/2.round + 1] ------Embedding ------[B, N, Emb2]\n",
    "                Identity embedding : learnable parameter [N, Emb3]\n",
    "                Time embedding : Week and Day : [N, 7] [N, 24(hour) * 12 (60min / 5min due to sampling)] ------Embedding ------ [N, 2 * Emb4]\n",
    "                Concat frequency domain information + Identity embedding + Time embedding ------Embedding , Activating, Normalization and Dropout\n",
    "                Conv1d to get adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: [B, L, N, 1]\n",
    "        \"\"\"\n",
    "        #num_feat = model_args[\"num_feat\"]\n",
    "        input = history_data.transpose(1, 3).contiguous()[:,0:2,:,:] # [B, C, N, L]\n",
    "        data = history_data\n",
    "\n",
    "        in_len = input.size(3)\n",
    "        if in_len < self.receptive_field:\n",
    "            x = nn.functional.pad(\n",
    "                input, (self.receptive_field-in_len, 0, 0, 0))\n",
    "        else:\n",
    "            x = input\n",
    "        x = self.start_conv(x)\n",
    "\n",
    "        skip = 0\n",
    "        if self.gcn_bool and self.addaptadj and self.supports is not None:\n",
    "\n",
    "\n",
    "            gwadp = F.softmax(\n",
    "                F.relu(torch.mm(self.nodevec1, self.nodevec2)), dim=1)\n",
    "\n",
    "            new_supports = self.supports + [gwadp] # pretrained graph in DCRNN and self-adaptive graph in GWNet\n",
    "\n",
    "            # Construction of dynamic frequency domain graph\n",
    "            xn1 = input[:, 0, :, -self.seq_len:]\n",
    "\n",
    "            T_D = self.T_i_D_emb[(data[:, :, :, 1]).type(torch.LongTensor)][:, -1, :, :]\n",
    "            D_W = self.D_i_W_emb[(data[:, :, :, 2]).type(torch.LongTensor)][:, -1, :, :]\n",
    "\n",
    "            xn1 = torch.fft.rfft(xn1, dim=-1)\n",
    "            xn1 = torch.abs(xn1)\n",
    "\n",
    "            xn1 = torch.nn.functional.normalize(xn1, p=2.0, dim=1, eps=1e-12, out=None)\n",
    "            xn1 = torch.nn.functional.normalize(xn1, p=2.0, dim=2, eps=1e-12, out=None) * self.a\n",
    "\n",
    "\n",
    "            xn1 = torch.matmul(xn1, self.Ex1)\n",
    "            xn1k = cat(xn1, self.node1)\n",
    "            x_n1 = torch.cat([xn1k, T_D, D_W], dim=2)\n",
    "            x1 = torch.bmm(x_n1.permute(1,0,2),self.Wd).permute(1,0,2)\n",
    "            x1 = torch.relu(x1)\n",
    "            x1k = self.layersnorm(x1)\n",
    "            x1k = self.drop(x1k)\n",
    "            adp = self.convt(x1k, self.Wxabs)\n",
    "            adj = torch.bmm(adp, x1.permute(0, 2, 1))\n",
    "            adp = torch.relu(adj)\n",
    "            adp = dy_mask_graph(adp, self.subgraph_size)\n",
    "            adp = F.softmax(adp, dim=2)\n",
    "\n",
    "            # adp = self.compute_dynamic_adj(history_data)\n",
    "            new_supports = new_supports + [adp]\n",
    "\n",
    "\n",
    "\n",
    "        # WaveNet layers\n",
    "        for i in range(self.blocks * self.layers):\n",
    "\n",
    "            #            |----------------------------------------|     *residual*\n",
    "            #            |                                        |\n",
    "            #            |    |-- conv -- tanh --|                |\n",
    "            # -> dilate -|----|                  * ----|-- 1x1 -- + -->\t*input*\n",
    "            #                 |-- conv -- sigm --|     |\n",
    "            #                                         1x1\n",
    "            #                                          |\n",
    "            # ---------------------------------------> + ------------->\t*skip*\n",
    "\n",
    "\n",
    "            # dilated convolution\n",
    "            residual = x\n",
    "            filter = self.filter_convs[i](residual)\n",
    "            filter = torch.tanh(filter)\n",
    "            gate = self.gate_convs[i](residual)\n",
    "            gate = torch.sigmoid(gate)\n",
    "            x = filter * gate\n",
    "\n",
    "            # parametrized skip connection\n",
    "\n",
    "            s = x\n",
    "\n",
    "            s = self.skip_convs[i](s)\n",
    "            try:\n",
    "                skip = skip[:, :, :,  -s.size(3):]\n",
    "\n",
    "            except:\n",
    "                skip = 0\n",
    "            skip = s + skip\n",
    "\n",
    "            if self.gcn_bool and self.supports is not None:\n",
    "                if self.addaptadj:\n",
    "                    x = self.gconv[i](x, new_supports)\n",
    "\n",
    "                else:\n",
    "                    x = self.gconv[i](x, self.supports)\n",
    "            else:\n",
    "                x = self.residual_convs[i](x)\n",
    "            x = x + residual[:, :, :, -x.size(3):]\n",
    "\n",
    "            x = self.bn[i](x)\n",
    "\n",
    "        x = F.relu(skip)\n",
    "        x = F.relu(self.end_conv_1(x))\n",
    "        x = self.end_conv_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GWNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nconv(nn.Module):\n",
    "    \"\"\"Graph conv operation.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(nconv, self).__init__()\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        x = torch.einsum('ncvl,vw->ncwl', (x, A))\n",
    "        return x.contiguous()\n",
    "\n",
    "\n",
    "class linear(nn.Module):\n",
    "    \"\"\"Linear layer.\"\"\"\n",
    "\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(linear, self).__init__()\n",
    "        self.mlp = torch.nn.Conv2d(c_in, c_out, kernel_size=(\n",
    "            1, 1), padding=(0, 0), stride=(1, 1), bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "class gcn(nn.Module):\n",
    "    \"\"\"Graph convolution network.\"\"\"\n",
    "\n",
    "    def __init__(self, c_in, c_out, dropout, support_len=3, order=2):\n",
    "        super(gcn, self).__init__()\n",
    "        self.nconv = nconv()\n",
    "        c_in = (order*support_len+1)*c_in\n",
    "        self.mlp = linear(c_in, c_out)\n",
    "        self.dropout = dropout\n",
    "        self.order = order\n",
    "\n",
    "    def forward(self, x, support):\n",
    "        out = [x]\n",
    "        for a in support:\n",
    "            x1 = self.nconv(x, a.to(x.device))\n",
    "            out.append(x1)\n",
    "            for k in range(2, self.order + 1):\n",
    "                x2 = self.nconv(x1, a.to(x.device))\n",
    "                out.append(x2)\n",
    "                x1 = x2\n",
    "\n",
    "        h = torch.cat(out, dim=1)\n",
    "        h = self.mlp(h)\n",
    "        h = F.dropout(h, self.dropout, training=self.training)\n",
    "        return h\n",
    "\n",
    "\n",
    "class GWNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper: Graph WaveNet for Deep Spatial-Temporal Graph Modeling\n",
    "    Link: https://arxiv.org/abs/1906.00121\n",
    "    Official Code: https://github.com/nnzhan/Graph-WaveNet/blob/master/model.py\n",
    "    Venue: IJCAI 2019\n",
    "    Task: Spatial-Temporal Forecasting\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_nodes, dropout=0.3, supports=None,\n",
    "                    gcn_bool=True, addaptadj=True, aptinit=None,\n",
    "                    in_dim=2, out_dim=12, residual_channels=32,\n",
    "                    dilation_channels=32, skip_channels=256, end_channels=512,\n",
    "                    kernel_size=2, blocks=4, layers=2, channels=[0], emb_dim=0, add_c=0):\n",
    "        super(GWNet, self).__init__()\n",
    "        self.time_embedding = nn.Embedding(288, emb_dim)\n",
    "        self.node_embedding = nn.Embedding(num_nodes, emb_dim)\n",
    "        self.channels = channels\n",
    "        self.dropout = dropout\n",
    "        self.blocks = blocks\n",
    "        self.layers = layers\n",
    "        self.gcn_bool = gcn_bool\n",
    "        self.addaptadj = addaptadj\n",
    "\n",
    "        self.filter_convs = nn.ModuleList()\n",
    "        self.gate_convs = nn.ModuleList()\n",
    "        self.residual_convs = nn.ModuleList()\n",
    "        self.skip_convs = nn.ModuleList()\n",
    "        self.bn = nn.ModuleList()\n",
    "        self.gconv = nn.ModuleList()\n",
    "\n",
    "        self.start_conv = nn.Conv2d(in_channels=in_dim+emb_dim+add_c,\n",
    "                                    out_channels=residual_channels,\n",
    "                                    kernel_size=(1, 1))\n",
    "        self.supports = supports\n",
    "\n",
    "        receptive_field = 1\n",
    "\n",
    "        self.supports_len = 0\n",
    "        if supports is not None:\n",
    "            self.supports_len += len(supports)\n",
    "\n",
    "        if gcn_bool and addaptadj:\n",
    "            if aptinit is None:\n",
    "                if supports is None:\n",
    "                    self.supports = []\n",
    "                self.nodevec1 = nn.Parameter(\n",
    "                    torch.randn(num_nodes, 10), requires_grad=True)\n",
    "                self.nodevec2 = nn.Parameter(\n",
    "                    torch.randn(10, num_nodes), requires_grad=True)\n",
    "                self.supports_len += 1\n",
    "            else:\n",
    "                if supports is None:\n",
    "                    self.supports = []\n",
    "                m, p, n = torch.svd(aptinit)\n",
    "                initemb1 = torch.mm(m[:, :10], torch.diag(p[:10] ** 0.5))\n",
    "                initemb2 = torch.mm(torch.diag(p[:10] ** 0.5), n[:, :10].t())\n",
    "                self.nodevec1 = nn.Parameter(initemb1, requires_grad=True)\n",
    "                self.nodevec2 = nn.Parameter(initemb2, requires_grad=True)\n",
    "                self.supports_len += 1\n",
    "\n",
    "        for b in range(blocks):\n",
    "            additional_scope = kernel_size - 1\n",
    "            new_dilation = 1\n",
    "            for i in range(layers):\n",
    "                # dilated convolutions\n",
    "                self.filter_convs.append(nn.Conv2d(in_channels=residual_channels,\n",
    "                                                   out_channels=dilation_channels,\n",
    "                                                   kernel_size=(1, kernel_size), dilation=new_dilation))\n",
    "\n",
    "                self.gate_convs.append(nn.Conv2d(in_channels=residual_channels,\n",
    "                                                 out_channels=dilation_channels,\n",
    "                                                 kernel_size=(1, kernel_size), dilation=new_dilation))\n",
    "\n",
    "                # 1x1 convolution for residual connection\n",
    "                self.residual_convs.append(nn.Conv2d(in_channels=dilation_channels,\n",
    "                                                     out_channels=residual_channels,\n",
    "                                                     kernel_size=(1, 1)))\n",
    "\n",
    "                # 1x1 convolution for skip connection\n",
    "                self.skip_convs.append(nn.Conv2d(in_channels=dilation_channels,\n",
    "                                                 out_channels=skip_channels,\n",
    "                                                 kernel_size=(1, 1)))\n",
    "                self.bn.append(nn.BatchNorm2d(residual_channels))\n",
    "                new_dilation *= 2\n",
    "                receptive_field += additional_scope\n",
    "                additional_scope *= 2\n",
    "                if self.gcn_bool:\n",
    "                    self.gconv.append(\n",
    "                        gcn(dilation_channels, residual_channels, dropout, support_len=self.supports_len))\n",
    "\n",
    "        self.end_conv_1 = nn.Conv2d(in_channels=skip_channels,\n",
    "                                    out_channels=end_channels,\n",
    "                                    kernel_size=(1, 1),\n",
    "                                    bias=True)\n",
    "\n",
    "        self.end_conv_2 = nn.Conv2d(in_channels=end_channels,\n",
    "                                    out_channels=out_dim,\n",
    "                                    kernel_size=(1, 1),\n",
    "                                    bias=True)\n",
    "\n",
    "        self.receptive_field = receptive_field\n",
    "\n",
    "    def forward(self, history_data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Feedforward function of Graph WaveNet.\n",
    "\n",
    "        Args:\n",
    "            history_data (torch.Tensor): shape [B, L, N, C]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: [B, 12, N, 1]  (если предсказываем 12 шагов вперед)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # Меняем местами оси: теперь C становится первым\n",
    "        input = history_data.transpose(1, 3).contiguous()#[:, self.channels, :, :]\n",
    "\n",
    "        # Проверяем длину временной последовательности\n",
    "        in_len = input.size(3)\n",
    "        if in_len < self.receptive_field:\n",
    "            x = nn.functional.pad(input, (self.receptive_field-in_len, 0, 0, 0))\n",
    "        else:\n",
    "            x = input\n",
    "\n",
    "        time_emb = self.time_embedding(x[:, 1, :, :].long())\n",
    "        time_emb = time_emb.permute(0, 3, 1, 2)\n",
    "        x = torch.cat([x[:, self.channels, :, :], time_emb], dim=1)  # Объединяем с входными данными\n",
    "\n",
    "        # node_emb = self.node_embedding(x[:, -1, :, :].long())\n",
    "        # node_emb = node_emb.permute(0, 3, 1, 2)\n",
    "        # x = torch.cat([x[:, self.channels, :, :], node_emb], dim=1)  # Объединяем с входными данными\n",
    "\n",
    "        # Применяем 1×1 свертку (изменение числа каналов)\n",
    "        x = self.start_conv(x)\n",
    "\n",
    "        skip = 0\n",
    "\n",
    "        # Вычисляем адаптивную матрицу смежности (если используется)\n",
    "        new_supports = None\n",
    "        if self.gcn_bool and self.addaptadj and self.supports is not None:\n",
    "            adp = F.softmax(F.relu(torch.mm(self.nodevec1, self.nodevec2)), dim=1)\n",
    "            new_supports = self.supports + [adp]\n",
    "\n",
    "        # WaveNet (TCN + GCN) слои\n",
    "        for i in range(self.blocks * self.layers):\n",
    "            residual = x\n",
    "\n",
    "            # Dilated TCN\n",
    "            filter = self.filter_convs[i](residual)\n",
    "            filter = torch.tanh(filter)\n",
    "            gate = self.gate_convs[i](residual)\n",
    "            gate = torch.sigmoid(gate)\n",
    "            x = filter * gate\n",
    "\n",
    "            s = self.skip_convs[i](x) # Skip connection\n",
    "            \n",
    "            try:\n",
    "                skip = skip[:, :, :, -s.size(3):]\n",
    "            except:\n",
    "                skip = 0\n",
    "            skip = s + skip\n",
    "\n",
    "            # Graph Convolution (GCN)\n",
    "            if self.gcn_bool and self.supports is not None:\n",
    "                if self.addaptadj:\n",
    "                    x = self.gconv[i](x, new_supports)\n",
    "                else:\n",
    "                    x = self.gconv[i](x, self.supports)\n",
    "            else:\n",
    "                x = self.residual_convs[i](x)\n",
    "\n",
    "            x = x + residual[:, :, :, -x.size(3):] # Residual connection\n",
    "            x = self.bn[i](x) # BatchNorm\n",
    "\n",
    "        x = F.relu(skip)\n",
    "\n",
    "        # Финальные 1×1 свертки\n",
    "        x = F.relu(self.end_conv_1(x))\n",
    "        x = self.end_conv_2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "GWNet                                    [16, 12, 358, 1]          19,904\n",
       "├─Embedding: 1-1                         [16, 358, 13, 12]         3,456\n",
       "├─Conv2d: 1-2                            [16, 32, 358, 13]         832\n",
       "├─ModuleList: 1-38                       --                        (recursive)\n",
       "│    └─Conv2d: 2-1                       [16, 32, 358, 12]         2,080\n",
       "├─ModuleList: 1-39                       --                        (recursive)\n",
       "│    └─Conv2d: 2-2                       [16, 32, 358, 12]         2,080\n",
       "├─ModuleList: 1-40                       --                        (recursive)\n",
       "│    └─Conv2d: 2-3                       [16, 256, 358, 12]        8,448\n",
       "├─ModuleList: 1-41                       --                        (recursive)\n",
       "│    └─gcn: 2-4                          [16, 32, 358, 12]         --\n",
       "│    │    └─nconv: 3-1                   [16, 32, 358, 12]         --\n",
       "│    │    └─nconv: 3-2                   [16, 32, 358, 12]         --\n",
       "│    │    └─linear: 3-3                  [16, 32, 358, 12]         3,104\n",
       "├─ModuleList: 1-42                       --                        (recursive)\n",
       "│    └─BatchNorm2d: 2-5                  [16, 32, 358, 12]         64\n",
       "├─ModuleList: 1-38                       --                        (recursive)\n",
       "│    └─Conv2d: 2-6                       [16, 32, 358, 10]         2,080\n",
       "├─ModuleList: 1-39                       --                        (recursive)\n",
       "│    └─Conv2d: 2-7                       [16, 32, 358, 10]         2,080\n",
       "├─ModuleList: 1-40                       --                        (recursive)\n",
       "│    └─Conv2d: 2-8                       [16, 256, 358, 10]        8,448\n",
       "├─ModuleList: 1-41                       --                        (recursive)\n",
       "│    └─gcn: 2-9                          [16, 32, 358, 10]         --\n",
       "│    │    └─nconv: 3-4                   [16, 32, 358, 10]         --\n",
       "│    │    └─nconv: 3-5                   [16, 32, 358, 10]         --\n",
       "│    │    └─linear: 3-6                  [16, 32, 358, 10]         3,104\n",
       "├─ModuleList: 1-42                       --                        (recursive)\n",
       "│    └─BatchNorm2d: 2-10                 [16, 32, 358, 10]         64\n",
       "├─ModuleList: 1-38                       --                        (recursive)\n",
       "│    └─Conv2d: 2-11                      [16, 32, 358, 9]          2,080\n",
       "├─ModuleList: 1-39                       --                        (recursive)\n",
       "│    └─Conv2d: 2-12                      [16, 32, 358, 9]          2,080\n",
       "├─ModuleList: 1-40                       --                        (recursive)\n",
       "│    └─Conv2d: 2-13                      [16, 256, 358, 9]         8,448\n",
       "├─ModuleList: 1-41                       --                        (recursive)\n",
       "│    └─gcn: 2-14                         [16, 32, 358, 9]          --\n",
       "│    │    └─nconv: 3-7                   [16, 32, 358, 9]          --\n",
       "│    │    └─nconv: 3-8                   [16, 32, 358, 9]          --\n",
       "│    │    └─linear: 3-9                  [16, 32, 358, 9]          3,104\n",
       "├─ModuleList: 1-42                       --                        (recursive)\n",
       "│    └─BatchNorm2d: 2-15                 [16, 32, 358, 9]          64\n",
       "├─ModuleList: 1-38                       --                        (recursive)\n",
       "│    └─Conv2d: 2-16                      [16, 32, 358, 7]          2,080\n",
       "├─ModuleList: 1-39                       --                        (recursive)\n",
       "│    └─Conv2d: 2-17                      [16, 32, 358, 7]          2,080\n",
       "├─ModuleList: 1-40                       --                        (recursive)\n",
       "│    └─Conv2d: 2-18                      [16, 256, 358, 7]         8,448\n",
       "├─ModuleList: 1-41                       --                        (recursive)\n",
       "│    └─gcn: 2-19                         [16, 32, 358, 7]          --\n",
       "│    │    └─nconv: 3-10                  [16, 32, 358, 7]          --\n",
       "│    │    └─nconv: 3-11                  [16, 32, 358, 7]          --\n",
       "│    │    └─linear: 3-12                 [16, 32, 358, 7]          3,104\n",
       "├─ModuleList: 1-42                       --                        (recursive)\n",
       "│    └─BatchNorm2d: 2-20                 [16, 32, 358, 7]          64\n",
       "├─ModuleList: 1-38                       --                        (recursive)\n",
       "│    └─Conv2d: 2-21                      [16, 32, 358, 6]          2,080\n",
       "├─ModuleList: 1-39                       --                        (recursive)\n",
       "│    └─Conv2d: 2-22                      [16, 32, 358, 6]          2,080\n",
       "├─ModuleList: 1-40                       --                        (recursive)\n",
       "│    └─Conv2d: 2-23                      [16, 256, 358, 6]         8,448\n",
       "├─ModuleList: 1-41                       --                        (recursive)\n",
       "│    └─gcn: 2-24                         [16, 32, 358, 6]          --\n",
       "│    │    └─nconv: 3-13                  [16, 32, 358, 6]          --\n",
       "│    │    └─nconv: 3-14                  [16, 32, 358, 6]          --\n",
       "│    │    └─linear: 3-15                 [16, 32, 358, 6]          3,104\n",
       "├─ModuleList: 1-42                       --                        (recursive)\n",
       "│    └─BatchNorm2d: 2-25                 [16, 32, 358, 6]          64\n",
       "├─ModuleList: 1-38                       --                        (recursive)\n",
       "│    └─Conv2d: 2-26                      [16, 32, 358, 4]          2,080\n",
       "├─ModuleList: 1-39                       --                        (recursive)\n",
       "│    └─Conv2d: 2-27                      [16, 32, 358, 4]          2,080\n",
       "├─ModuleList: 1-40                       --                        (recursive)\n",
       "│    └─Conv2d: 2-28                      [16, 256, 358, 4]         8,448\n",
       "├─ModuleList: 1-41                       --                        (recursive)\n",
       "│    └─gcn: 2-29                         [16, 32, 358, 4]          --\n",
       "│    │    └─nconv: 3-16                  [16, 32, 358, 4]          --\n",
       "│    │    └─nconv: 3-17                  [16, 32, 358, 4]          --\n",
       "│    │    └─linear: 3-18                 [16, 32, 358, 4]          3,104\n",
       "├─ModuleList: 1-42                       --                        (recursive)\n",
       "│    └─BatchNorm2d: 2-30                 [16, 32, 358, 4]          64\n",
       "├─ModuleList: 1-38                       --                        (recursive)\n",
       "│    └─Conv2d: 2-31                      [16, 32, 358, 3]          2,080\n",
       "├─ModuleList: 1-39                       --                        (recursive)\n",
       "│    └─Conv2d: 2-32                      [16, 32, 358, 3]          2,080\n",
       "├─ModuleList: 1-40                       --                        (recursive)\n",
       "│    └─Conv2d: 2-33                      [16, 256, 358, 3]         8,448\n",
       "├─ModuleList: 1-41                       --                        (recursive)\n",
       "│    └─gcn: 2-34                         [16, 32, 358, 3]          --\n",
       "│    │    └─nconv: 3-19                  [16, 32, 358, 3]          --\n",
       "│    │    └─nconv: 3-20                  [16, 32, 358, 3]          --\n",
       "│    │    └─linear: 3-21                 [16, 32, 358, 3]          3,104\n",
       "├─ModuleList: 1-42                       --                        (recursive)\n",
       "│    └─BatchNorm2d: 2-35                 [16, 32, 358, 3]          64\n",
       "├─ModuleList: 1-38                       --                        (recursive)\n",
       "│    └─Conv2d: 2-36                      [16, 32, 358, 1]          2,080\n",
       "├─ModuleList: 1-39                       --                        (recursive)\n",
       "│    └─Conv2d: 2-37                      [16, 32, 358, 1]          2,080\n",
       "├─ModuleList: 1-40                       --                        (recursive)\n",
       "│    └─Conv2d: 2-38                      [16, 256, 358, 1]         8,448\n",
       "├─ModuleList: 1-41                       --                        (recursive)\n",
       "│    └─gcn: 2-39                         [16, 32, 358, 1]          --\n",
       "│    │    └─nconv: 3-22                  [16, 32, 358, 1]          --\n",
       "│    │    └─nconv: 3-23                  [16, 32, 358, 1]          --\n",
       "│    │    └─linear: 3-24                 [16, 32, 358, 1]          3,104\n",
       "├─ModuleList: 1-42                       --                        (recursive)\n",
       "│    └─BatchNorm2d: 2-40                 [16, 32, 358, 1]          64\n",
       "├─Conv2d: 1-43                           [16, 512, 358, 1]         131,584\n",
       "├─Conv2d: 1-44                           [16, 12, 358, 1]          6,156\n",
       "==========================================================================================\n",
       "Total params: 288,140\n",
       "Trainable params: 288,140\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.53\n",
       "==========================================================================================\n",
       "Input size (MB): 4.12\n",
       "Forward/backward pass size (MB): 965.24\n",
       "Params size (MB): 1.07\n",
       "Estimated Total Size (MB): 970.43\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "# === Определение устройства === \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# === Фиксируем adjacency matrix === \n",
    "adj = adj.clone().detach().to(torch.float32).to(device) if isinstance(adj, torch.Tensor) else torch.tensor(adj, dtype=torch.float32).to(device)\n",
    "supports = [adj]\n",
    "\n",
    "# === Гиперпараметры === \n",
    "num_nodes = train_data.shape[1]\n",
    "input_dim = 4  # Например, только скорость\n",
    "hidden_dim = 64\n",
    "output_dim = 1\n",
    "num_layers = 2\n",
    "pre_len = pred_len\n",
    "seq_len = train_data.shape[2]  # Длина входной последовательности\n",
    "channels = [0,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "in_dim = len(channels)\n",
    "\n",
    "# === Конфигурация эмбеддингов === \n",
    "emb_configs = {\n",
    "    # 1: (288, 5),\n",
    "    # 2: (7, 5),\n",
    "    # 3: (3, 5),\n",
    "    # 4: (N, 5),\n",
    "}\n",
    "\n",
    "# === Функция выбора модели ===\n",
    "def get_model(model_name):\n",
    "    if model_name == \"QGNNTrafficPredictor\":\n",
    "        return QGNNTrafficPredictor(adj, num_nodes, input_dim, hidden_dim, output_dim, num_layers, seq_len, pre_len, emb_configs).to(device)\n",
    "    elif model_name == \"DFDGCN\":\n",
    "        return DFDGCN(num_nodes, dropout=0.3, gcn_bool=True, addaptadj=True, aptinit=None,\n",
    "                      in_dim=2, out_dim=12, residual_channels=32, dilation_channels=32, skip_channels=256,\n",
    "                      end_channels=512, kernel_size=2, blocks=4, layers=2, a=1, seq_len=seq_len, affine=True,\n",
    "                      fft_emb=10, identity_emb=10, hidden_emb=30, subgraph=20, alpha=0.001, window_size=3).to(device)\n",
    "    elif model_name == \"GWNet\":\n",
    "        return GWNet(num_nodes, in_dim=in_dim, channels=channels, emb_dim=12).to(device)\n",
    "    else:\n",
    "        raise ValueError(f\"Неизвестное имя модели: {model_name}\")\n",
    "\n",
    "# === Выбор модели ===\n",
    "model_name = \"GWNet\"  # Здесь можно менять модель\n",
    "model = get_model(model_name)\n",
    "\n",
    "# === Оптимизатор и функция потерь ===\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# === Тестовый вызов модели ===\n",
    "train_iter = iter(train_loader)\n",
    "history_data = next(train_iter)[0].to(device)  # Получаем один батч данных\n",
    "summary(model, input_data=history_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация TensorBoard и функция запуска обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(output, target):\n",
    "    \"\"\"Вычисление метрик MAE, RMSE, MAPE.\"\"\"\n",
    "    abs_error = torch.abs(output - target).sum().item()\n",
    "    mae = abs_error / len(target)\n",
    "    rmse = ((output - target) ** 2).sum().item() / len(target)\n",
    "    rmse = rmse ** 0.5\n",
    "    mape = (abs_error / torch.abs(target).sum().item()) if torch.abs(target).sum().item() != 0 else 0\n",
    "    return mae, rmse, mape\n",
    "\n",
    "def train_val_test_model(model, train_loader, val_loader, test_loader, epochs, writer):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # === Тренировка ===\n",
    "        model.train()\n",
    "        train_loss, train_mae, train_rmse, train_mape = 0.0, 0.0, 0.0, 0.0\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Training\", leave=False)\n",
    "\n",
    "        for x, y in train_loader_tqdm:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x).squeeze(-1)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "\n",
    "            mae, rmse, mape = compute_metrics(output, y)\n",
    "            train_mae += mae\n",
    "            train_rmse += rmse\n",
    "            train_mape += mape\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_mae /= len(train_loader)\n",
    "        train_rmse /= len(train_loader)\n",
    "        train_mape /= len(train_loader)\n",
    "\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch + 1)\n",
    "        writer.add_scalar(\"MAE/Train\", train_mae, epoch + 1)\n",
    "        writer.add_scalar(\"RMSE/Train\", train_rmse, epoch + 1)\n",
    "        writer.add_scalar(\"MAPE/Train\", train_mape, epoch + 1)\n",
    "\n",
    "        # === Валидация ===\n",
    "        model.eval()\n",
    "        val_loss, val_mae, val_rmse, val_mape = 0.0, 0.0, 0.0, 0.0\n",
    "        val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Validation\", leave=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader_tqdm:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = model(x).squeeze(-1)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item() * x.size(0)\n",
    "\n",
    "                mae, rmse, mape = compute_metrics(output, y)\n",
    "                val_mae += mae\n",
    "                val_rmse += rmse\n",
    "                val_mape += mape\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_mae /= len(val_loader)\n",
    "        val_rmse /= len(val_loader)\n",
    "        val_mape /= len(val_loader)\n",
    "\n",
    "        writer.add_scalar(\"Loss/Validation\", val_loss, epoch + 1)\n",
    "        writer.add_scalar(\"MAE/Validation\", val_mae, epoch + 1)\n",
    "        writer.add_scalar(\"RMSE/Validation\", val_rmse, epoch + 1)\n",
    "        writer.add_scalar(\"MAPE/Validation\", val_mape, epoch + 1)\n",
    "\n",
    "        # === Тестирование ===\n",
    "        test_loss, test_mae, test_rmse, test_mape = 0.0, 0.0, 0.0, 0.0\n",
    "        test_loader_tqdm = tqdm(test_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Testing\", leave=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader_tqdm:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = model(x).squeeze(-1)\n",
    "                loss = criterion(output, y)\n",
    "                test_loss += loss.item() * x.size(0)\n",
    "\n",
    "                mae, rmse, mape = compute_metrics(output, y)\n",
    "                test_mae += mae\n",
    "                test_rmse += rmse\n",
    "                test_mape += mape\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_mae /= len(test_loader)\n",
    "        test_rmse /= len(test_loader)\n",
    "        test_mape /= len(test_loader)\n",
    "\n",
    "        writer.add_scalar(\"Loss/Test\", test_loss, epoch + 1)\n",
    "        writer.add_scalar(\"MAE/Test\", test_mae, epoch + 1)\n",
    "        writer.add_scalar(\"RMSE/Test\", test_rmse, epoch + 1)\n",
    "        writer.add_scalar(\"MAPE/Test\", test_mape, epoch + 1)\n",
    "\n",
    "        # Сохранение лучшей модели\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f\"{writer.log_dir}best_model.pth\")\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение, валидация и тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    }
   ],
   "source": [
    "# Инициализация TensorBoard\n",
    "writer = SummaryWriter(log_dir=f\"runs/T-GCN/GWNet wo adj lagged 1-15 D_EMB PEMS03/\")\n",
    "train_val_test_model(model, train_loader, val_loader, test_loader, epochs=80, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Маскирование данных после обучения\n",
    "\n",
    "В теории, это должно помочь оценить, какие признаки дали свой вклад, если они были :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перевод модели в режим тестирования\n",
    "writer = SummaryWriter(log_dir=f\"runs/T-GCN/removed_channel1 test/\")\n",
    "model.eval()\n",
    "\n",
    "# Подсчёт метрик для всех батчей\n",
    "test_loss, test_mae, test_rmse, test_mape = 0.0, 0.0, 0.0, 0.0\n",
    "total_batches = len(test_loader)\n",
    "\n",
    "# Пройдем все батчи и вычислим метрики\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (history_data, target) in enumerate(test_loader):\n",
    "        history_data, target = history_data.to(device), target.to(device)\n",
    "\n",
    "        # Прогноз\n",
    "        output = model(history_data, removed_channel=1).squeeze(-1)  # removed_channel=1, чтобы исключить канал N=1\n",
    "        \n",
    "        # Вычисление потерь и метрик\n",
    "        loss = criterion(output, target)\n",
    "        mae, rmse, mape = compute_metrics(output, target)\n",
    "\n",
    "        # Добавляем в общие метрики\n",
    "        test_loss += loss.item() * history_data.size(0)\n",
    "        test_mae += mae\n",
    "        test_rmse += rmse\n",
    "        test_mape += mape\n",
    "\n",
    "        # Запись метрик в TensorBoard для текущего батча\n",
    "        writer.add_scalar(\"Loss/Test\", loss.item(), batch_idx + 1)\n",
    "        writer.add_scalar(\"MAE/Test\", mae, batch_idx + 1)\n",
    "        writer.add_scalar(\"RMSE/Test\", rmse, batch_idx + 1)\n",
    "        writer.add_scalar(\"MAPE/Test\", mape, batch_idx + 1)\n",
    "\n",
    "# Средние метрики по всем батчам\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_mae /= total_batches\n",
    "test_rmse /= total_batches\n",
    "test_mape /= total_batches\n",
    "\n",
    "# Запись средней метрики в TensorBoard\n",
    "writer.add_scalar(\"Loss/Test_Avg\", test_loss, 0)\n",
    "writer.add_scalar(\"MAE/Test_Avg\", test_mae, 0)\n",
    "writer.add_scalar(\"RMSE/Test_Avg\", test_rmse, 0)\n",
    "writer.add_scalar(\"MAPE/Test_Avg\", test_mape, 0)\n",
    "\n",
    "# Закрытие TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "# Вывод финальных результатов\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}, Test RMSE: {test_rmse:.4f}, Test MAPE: {test_mape:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
