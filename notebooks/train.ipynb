{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Добавляем путь на уровень выше\n",
    "sys.path.append(str(Path(os.getcwd()).resolve().parent))\n",
    "\n",
    "from utils.features import *\n",
    "from utils.load_data import load_all_data\n",
    "from models.dfdgcn import DFDGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/PEMS-BAY')\n",
    "metadata, data, adj = load_all_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster  import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3b67a161c94e3ca0e497983f940df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "G = nx.from_numpy_array(adj)\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, p=1, q=1, workers=12)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "node_embeddings = np.array([model.wv[str(node)] for node in G.nodes()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходные данные (временные ряды): (2016, 325, 67)\n",
      "Эмбеддинги узлов: (325, 64)\n",
      "Объединённые данные: (2016, 325, 67)\n"
     ]
    }
   ],
   "source": [
    "node_embeddings_expanded = np.expand_dims(node_embeddings, axis=0)  # Форма: (1, 325, 64)\n",
    "node_embeddings_expanded = np.repeat(node_embeddings_expanded, data.shape[0], axis=0)  # Форма: (2016, 325, 64)\n",
    "\n",
    "# 4. Объединение с временными рядами по последней оси\n",
    "data = np.concatenate([data, node_embeddings_expanded], axis=-1)  # Форма: (2016, 325, 3 + 64)\n",
    "\n",
    "# 5. Проверка результата\n",
    "print(\"Исходные данные (временные ряды):\", data.shape)\n",
    "print(\"Эмбеддинги узлов:\", node_embeddings.shape)\n",
    "print(\"Объединённые данные:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from ..models.dfdgcn import DFDGCN\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Данные и параметры\n",
    "L, N, C = data.shape  # [2016, 325, C]\n",
    "batch_size = 16\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "seq_len = 12  # Количество временных шагов на вход\n",
    "pred_len = 12  # Количество временных шагов для предсказания\n",
    "\n",
    "# Индексы каналов для нормализации\n",
    "normalize = True\n",
    "\n",
    "channels_to_normalize = [0] #+ [i for i in range(3, 64)]\n",
    "\n",
    "# Проверка корректности разделения данных\n",
    "assert train_ratio + val_ratio + test_ratio == 1.0, \"Сумма долей train, val и test должна быть равна 1.0\"\n",
    "\n",
    "# Разделение данных на train, val и test\n",
    "num_samples = data.shape[0]  # Количество временных шагов (L)\n",
    "train_size = int(num_samples * train_ratio)\n",
    "val_size = int(num_samples * val_ratio)\n",
    "test_size = num_samples - train_size - val_size\n",
    "\n",
    "train_data = data[:train_size, :, :]  # [train_size, N, C]\n",
    "val_data = data[train_size:train_size + val_size, :, :]  # [val_size, N, C]\n",
    "test_data = data[train_size + val_size:, :, :]  # [test_size, N, C]\n",
    "\n",
    "# Убедитесь, что данные имеют разрешение на запись\n",
    "train_data = train_data.copy()\n",
    "val_data = val_data.copy()\n",
    "test_data = test_data.copy()\n",
    "\n",
    "# Нормализация данных\n",
    "if normalize:\n",
    "    assert all(0 <= ch < C for ch in channels_to_normalize), \"Индексы каналов выходят за пределы допустимого диапазона\"\n",
    "    channel_max = train_data[:, :, channels_to_normalize].max(axis=(0, 1), keepdims=True)  # Форма [1, 1, len(channels_to_normalize)]\n",
    "    channel_max[channel_max == 0] = 1.0\n",
    "    train_data[:, :, channels_to_normalize] = train_data[:, :, channels_to_normalize] / channel_max\n",
    "    val_data[:, :, channels_to_normalize] = val_data[:, :, channels_to_normalize] / channel_max\n",
    "    test_data[:, :, channels_to_normalize] = test_data[:, :, channels_to_normalize] / channel_max\n",
    "\n",
    "\n",
    "# Создание кастомного Dataset\n",
    "class TrafficDataset(Dataset):\n",
    "    def __init__(self, data, seq_len, pred_len):\n",
    "        super().__init__()\n",
    "        self.data = data  # Форма [L, N, C]\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "    def __len__(self):\n",
    "        # Количество возможных последовательностей\n",
    "        return self.data.shape[0] - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Извлекаем последовательность входных данных\n",
    "        x = self.data[idx:idx + self.seq_len, :, :]  # Форма [seq_len, N, C]\n",
    "        # Извлекаем целевую последовательность\n",
    "        y = self.data[idx + self.seq_len:idx + self.seq_len + self.pred_len, :, 0]  # Форма [pred_len, N, C]\n",
    "        return x, y\n",
    "\n",
    "# Создание DataLoader\n",
    "train_dataset = TrafficDataset(train_data, seq_len, pred_len)\n",
    "val_dataset = TrafficDataset(val_data, seq_len, pred_len)\n",
    "test_dataset = TrafficDataset(test_data, seq_len, pred_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 12, 325, 3]) torch.Size([16, 12, 325])\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Определение устройства\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# Обновление модели, данных и вычислений\n",
    "supports = [torch.tensor(adj, dtype=torch.float32)]\n",
    "model = DFDGCN(num_nodes=N, supports=supports, in_dim=C, out_dim=pred_len).to(device)\n",
    "criterion = nn.MSELoss()  # Функция потерь\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "# Инициализация TensorBoard\n",
    "writer = SummaryWriter(log_dir=f\"runs/original/\")\n",
    "\n",
    "def compute_metrics(output, target):\n",
    "    \"\"\"Вычисление метрик MAE, RMSE, MAPE.\"\"\"\n",
    "    abs_error = torch.abs(output - target).sum().item()\n",
    "    mae = abs_error / len(target)\n",
    "    rmse = ((output - target) ** 2).sum().item() / len(target)\n",
    "    rmse = rmse ** 0.5\n",
    "    mape = (abs_error / torch.abs(target).sum().item()) if torch.abs(target).sum().item() != 0 else 0\n",
    "    return mae, rmse, mape\n",
    "\n",
    "def train_val_test_model(model, train_loader, val_loader, test_loader, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # === Тренировка ===\n",
    "        model.train()\n",
    "        train_loss, train_mae, train_rmse, train_mape = 0.0, 0.0, 0.0, 0.0\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Training\", leave=False)\n",
    "\n",
    "        for x, y in train_loader_tqdm:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x).squeeze(-1)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "\n",
    "            mae, rmse, mape = compute_metrics(output, y)\n",
    "            train_mae += mae\n",
    "            train_rmse += rmse\n",
    "            train_mape += mape\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_mae /= len(train_loader)\n",
    "        train_rmse /= len(train_loader)\n",
    "        train_mape /= len(train_loader)\n",
    "\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch + 1)\n",
    "        writer.add_scalar(\"MAE/Train\", train_mae, epoch + 1)\n",
    "        writer.add_scalar(\"RMSE/Train\", train_rmse, epoch + 1)\n",
    "        writer.add_scalar(\"MAPE/Train\", train_mape, epoch + 1)\n",
    "\n",
    "        # === Валидация ===\n",
    "        model.eval()\n",
    "        val_loss, val_mae, val_rmse, val_mape = 0.0, 0.0, 0.0, 0.0\n",
    "        val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Validation\", leave=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader_tqdm:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = model(x).squeeze(-1)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item() * x.size(0)\n",
    "\n",
    "                mae, rmse, mape = compute_metrics(output, y)\n",
    "                val_mae += mae\n",
    "                val_rmse += rmse\n",
    "                val_mape += mape\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_mae /= len(val_loader)\n",
    "        val_rmse /= len(val_loader)\n",
    "        val_mape /= len(val_loader)\n",
    "\n",
    "        writer.add_scalar(\"Loss/Validation\", val_loss, epoch + 1)\n",
    "        writer.add_scalar(\"MAE/Validation\", val_mae, epoch + 1)\n",
    "        writer.add_scalar(\"RMSE/Validation\", val_rmse, epoch + 1)\n",
    "        writer.add_scalar(\"MAPE/Validation\", val_mape, epoch + 1)\n",
    "\n",
    "        # === Тестирование ===\n",
    "        test_loss, test_mae, test_rmse, test_mape = 0.0, 0.0, 0.0, 0.0\n",
    "        test_loader_tqdm = tqdm(test_loader, desc=f\"Epoch {epoch + 1}/{epochs} - Testing\", leave=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader_tqdm:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                output = model(x).squeeze(-1)\n",
    "                loss = criterion(output, y)\n",
    "                test_loss += loss.item() * x.size(0)\n",
    "\n",
    "                mae, rmse, mape = compute_metrics(output, y)\n",
    "                test_mae += mae\n",
    "                test_rmse += rmse\n",
    "                test_mape += mape\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_mae /= len(test_loader)\n",
    "        test_rmse /= len(test_loader)\n",
    "        test_mape /= len(test_loader)\n",
    "\n",
    "        writer.add_scalar(\"Loss/Test\", test_loss, epoch + 1)\n",
    "        writer.add_scalar(\"MAE/Test\", test_mae, epoch + 1)\n",
    "        writer.add_scalar(\"RMSE/Test\", test_rmse, epoch + 1)\n",
    "        writer.add_scalar(\"MAPE/Test\", test_mape, epoch + 1)\n",
    "\n",
    "        # Сохранение лучшей модели\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    }
   ],
   "source": [
    "train_val_test_model(model, train_loader, val_loader, test_loader, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
